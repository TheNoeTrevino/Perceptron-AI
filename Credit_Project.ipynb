{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noetr\\AppData\\Local\\Temp\\ipykernel_21452\\150853685.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning column names from dataset details\n",
    "column_names = [\n",
    "    'CheckingAccountStatus', 'Duration', 'CreditHistory', 'Purpose', 'CreditAmount',\n",
    "    'SavingsAccountBonds', 'PresentEmploymentSince', 'InstallmentRatePercentage',\n",
    "    'PersonalStatusSex', 'OtherDebtorsGuarantors', 'PresentResidenceSince',\n",
    "    'Property', 'Age', 'OtherInstallmentPlans', 'Housing', 'NumberOfExistingCreditsAtBank',\n",
    "    'Job', 'NumberOfPeopleLiable', 'Telephone', 'ForeignWorker', 'LoanApproval'\n",
    "]\n",
    "\n",
    "#identifying categorical columns for hot encoding\n",
    "categorical_columns = [\n",
    "    'CheckingAccountStatus', 'CreditHistory', 'Purpose', 'SavingsAccountBonds',\n",
    "    'PresentEmploymentSince', 'PersonalStatusSex', 'OtherDebtorsGuarantors',\n",
    "    'Property', 'OtherInstallmentPlans', 'Housing', 'Job', 'Telephone', 'ForeignWorker'\n",
    "]\n",
    "\n",
    "dataset = pd.read_csv('german_credit_data.csv', header = None, names = column_names) #column names\n",
    "\n",
    "#X = dataset.iloc[:, :-1].values #all rows, EXCEPT last column for independent variable\n",
    "#y = dataset.iloc[:, -1].values #all rows, and just last column for depent variable vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CheckingAccountStatus  Duration CreditHistory Purpose  CreditAmount  \\\n",
      "0                   A11         6           A34     A43          1169   \n",
      "1                   A12        48           A32     A43          5951   \n",
      "2                   A14        12           A34     A46          2096   \n",
      "3                   A11        42           A32     A42          7882   \n",
      "4                   A11        24           A33     A40          4870   \n",
      "\n",
      "  SavingsAccountBonds PresentEmploymentSince  InstallmentRatePercentage  \\\n",
      "0                 A65                    A75                          4   \n",
      "1                 A61                    A73                          2   \n",
      "2                 A61                    A74                          2   \n",
      "3                 A61                    A74                          2   \n",
      "4                 A61                    A73                          3   \n",
      "\n",
      "  PersonalStatusSex OtherDebtorsGuarantors  ...  Property Age  \\\n",
      "0               A93                   A101  ...      A121  67   \n",
      "1               A92                   A101  ...      A121  22   \n",
      "2               A93                   A101  ...      A121  49   \n",
      "3               A93                   A103  ...      A122  45   \n",
      "4               A93                   A101  ...      A124  53   \n",
      "\n",
      "   OtherInstallmentPlans Housing NumberOfExistingCreditsAtBank   Job  \\\n",
      "0                   A143    A152                             2  A173   \n",
      "1                   A143    A152                             1  A173   \n",
      "2                   A143    A152                             1  A172   \n",
      "3                   A143    A153                             1  A173   \n",
      "4                   A143    A153                             2  A173   \n",
      "\n",
      "  NumberOfPeopleLiable  Telephone ForeignWorker LoanApproval  \n",
      "0                    1       A192          A201            1  \n",
      "1                    1       A191          A201            2  \n",
      "2                    2       A191          A201            1  \n",
      "3                    2       A191          A201            1  \n",
      "4                    2       A191          A201            2  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 4.800e+01 5.951e+03\n",
      " 2.000e+00 2.000e+00 2.200e+01 1.000e+00 1.000e+00]\n"
     ]
    }
   ],
   "source": [
    "# encoding categorical data\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), categorical_columns)], remainder='passthrough')\n",
    "\n",
    "X = ct.fit_transform(dataset.drop(['LoanApproval'], axis=1))\n",
    "y = dataset['LoanApproval'].values\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training, Test, and Validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#60/20/20 training split. train/validation/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitting twice for 60/20/20 split\n",
    "X_leftover, X_test, y_leftover, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) #800 leftover 200 test\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_leftover, y_leftover, test_size = 0.25, random_state = 0) #25% valid, 75% test, 200, 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#checking lengths just in case\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_valid))\n",
    "print(len(y_valid))\n",
    "print(len(X_test))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking Care of Misssing Data (R1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckingAccountStatus            0\n",
      "Duration                         0\n",
      "CreditHistory                    0\n",
      "Purpose                          0\n",
      "CreditAmount                     0\n",
      "SavingsAccountBonds              0\n",
      "PresentEmploymentSince           0\n",
      "InstallmentRatePercentage        0\n",
      "PersonalStatusSex                0\n",
      "OtherDebtorsGuarantors           0\n",
      "PresentResidenceSince            0\n",
      "Property                         0\n",
      "Age                              0\n",
      "OtherInstallmentPlans            0\n",
      "Housing                          0\n",
      "NumberOfExistingCreditsAtBank    0\n",
      "Job                              0\n",
      "NumberOfPeopleLiable             0\n",
      "Telephone                        0\n",
      "ForeignWorker                    0\n",
      "LoanApproval                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checkl if there is any missing data\n",
    "missing_values = dataset.isnull().sum()\n",
    "print(missing_values)\n",
    "# none was found!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking Care of Missing Data (none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none was found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Generating Perceptron Model and Deploying on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Validation F1 Score: 0.7749197860962568\n",
      "Inital Validation F1 Scores for Each Class: [0.82575758 0.66176471]\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Perceptron model on scaled data\n",
    "perceptron = Perceptron(max_iter=1000, tol=1e-3, random_state=0)\n",
    "\n",
    "perceptron.fit(X_train, y_train)\n",
    "y_pred_valid = perceptron.predict(X_valid)\n",
    "\n",
    "#printing out initial validation scores\n",
    "print(f\"Initial Validation F1 Score: {f1_score(y_valid, y_pred_valid, average='weighted')}\")\n",
    "f1_scores_per_class = f1_score(y_valid, y_pred_valid, average=None)\n",
    "print(\"Inital Validation F1 Scores for Each Class:\", f1_scores_per_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SMOTENC to Balance the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19]\n",
      "original:  Counter({1: 420, 2: 180})\n",
      "oversampled:  Counter({1: 420, 2: 420})\n"
     ]
    }
   ],
   "source": [
    "# finding indicies\n",
    "categorical_feature_indices = [column_names.index(col) for col in categorical_columns]\n",
    "print(categorical_feature_indices)\n",
    "\n",
    "# balancing the dataset\n",
    "smotenc = SMOTENC(categorical_features=categorical_feature_indices, random_state=42, sampling_strategy=1, k_neighbors=3)\n",
    "X_train_resampled, y_train_resampled = smotenc.fit_resample(X_train, y_train)\n",
    "\n",
    "#printing the amount for each class before and after balancing\n",
    "print('original: ', Counter(y_train))\n",
    "print('oversampled: ', Counter(y_train_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating NEW Linear Perceptron on the Oversampled Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making New Perceptron Model and Displaying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-SMOTENC Test F1 Score: 0.6648871527777778\n",
      "Post-SMOTENC Test F1 Scores for Each Class: [0.7265625  0.51388889]\n"
     ]
    }
   ],
   "source": [
    "# generate new linear perceptron model on oversampled data set\n",
    "perceptron.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_test = perceptron.predict(X_test)\n",
    "\n",
    "#printing scores for each class post smotenc\n",
    "print(f\"Post-SMOTENC Test F1 Score: {f1_score(y_test, y_pred_test, average='weighted')}\")\n",
    "f1_scores_per_class = f1_score(y_test, y_pred_test, average=None)\n",
    "print(\"Post-SMOTENC Test F1 Scores for Each Class:\", f1_scores_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My approach to finding the least significant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first: I decided to mimic the approach of the cortnory heart diease we discussed in class. I will use the pandas library to find the highly correlated features, and remove the least signifiant ones. As we saw in the heart diease example, just because a feature impacts the target variable, doesn't necessarily mean it is the most significant. This is due to the correlation between features. I could not find correlation, I might have done it wrong, but removal of features one by one did no change the F1 scores of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idenfitying the Least Significant Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score with Selected Features: 0.6375311225023538\n",
      "Mask of Selected Features: [False False  True  True  True False False False False False  True False\n",
      " False  True False False False  True  True  True  True  True  True  True\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False  True  True  True  True False False False\n",
      " False]\n",
      "Ranking of Features: [37  3  1  1  1 40 41 35  5 34  1 17 19  1  6 26 31  1  1  1  1  1  1  1\n",
      " 10 42 30  4 11 18 32 25 29 20 24  1  9 22 21 13 39 12 38 43  2  1 44 27\n",
      " 23 15 36  8 28  1  1  1  1  7 14 16 33]\n",
      "Indices of Selected Features: [2, 3, 4, 10, 13, 17, 18, 19, 20, 21, 22, 23, 35, 45, 53, 54, 55, 56]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# slsect 20 for n features, then 20. Which ever dont show up are least sig predictors\n",
    "selector = RFE(perceptron, n_features_to_select=18, step=1)\n",
    "selector = selector.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# transform the training and test sets to keep only the selected features\n",
    "X_train_selected = selector.transform(X_train_resampled)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# new perceptron\n",
    "perceptron.fit(X_train_selected, y_train_resampled)\n",
    "y_pred_test = perceptron.predict(X_test_selected)\n",
    "\n",
    "# print f1 scores here\n",
    "print(f\"F1 Score with Selected Features: {f1_score(y_test, y_pred_test, average='weighted')}\")\n",
    "\n",
    "# to see which features were selected\n",
    "print(f\"Mask of Selected Features: {selector.support_}\")\n",
    "print(f\"Ranking of Features: {selector.ranking_}\")\n",
    "\n",
    "# to get the indices of selected features, if needed\n",
    "selected_features_indices = [i for i, x in enumerate(selector.support_) if x]\n",
    "print(f\"Indices of Selected Features: {selected_features_indices}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing why the two features are the least significant. For example, in the cortnory heart diesease, the obesity and smoking(?) were not significant because they were so highly correlated with the family history. What relations can you find here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Two Least Significant Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the features and displaying F values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score after dropping least significant features: 0.6800\n",
      "Test F1 Scores for Each Class After Dropping: [0.77464789 0.44827586]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# indices 42 qand 40\n",
    "\n",
    "# drop the two least significant features: indices 40 and 42 (adjust for 0-based indexing if necessary)\n",
    "X_train_resampled_dropped = np.delete(X_train_resampled, [40, 42], axis=1)\n",
    "X_test_dropped = np.delete(X_test, [40, 42], axis=1)\n",
    "\n",
    "# new perceptron\n",
    "perceptron = Perceptron(max_iter=1000, tol=1e-3, random_state=0)\n",
    "perceptron.fit(X_train_resampled_dropped, y_train_resampled)\n",
    "y_pred = perceptron.predict(X_test_dropped)\n",
    "\n",
    "#print f1 scores here\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1 Score after dropping least significant features: {f1:.4f}\")\n",
    "f1_scores_per_class = f1_score(y_test, y_pred, average=None)\n",
    "print(\"Test F1 Scores for Each Class After Dropping:\", f1_scores_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the Two Most Significant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of the two most significant predictors: [ 2 53]\n",
      "Coefficients of the two most significant predictors: [12.        15.0123859]\n"
     ]
    }
   ],
   "source": [
    "# using coefficient to find least significant predictors \n",
    "importance = np.abs(perceptron.coef_[0])\n",
    "\n",
    "# get indices of the two features with the highest coefficients\n",
    "top2_indices = np.argsort(importance)[-2:]\n",
    "\n",
    "print(f\"Indices of the two most significant predictors: {top2_indices}\")\n",
    "print(f\"Coefficients of the two most significant predictors: {importance[top2_indices]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the method, together with your reasoning as to why the 2 features are the most significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enter your reasoning here noe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning the Oversampling Ratio and n-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Grid Search on the Validation Set to find optimal tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 420, 2: 180})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'smotenc__k_neighbors': 10, 'smotenc__sampling_strategy': 0.8}\n",
      "Validation F1 Score with GridSearch Optimized SMOTENC: 0.7479\n",
      "Validation F1 Scores for Each Class with GridSearch Optimized SMOTENC: [0.796875   0.63888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "180 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 322, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 258, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 1050, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 108, in fit_resample\n",
      "    self.sampling_strategy_ = check_sampling_strategy(\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\utils\\_validation.py\", line 571, in check_sampling_strategy\n",
      "    _sampling_strategy_float(sampling_strategy, y, sampling_type).items()\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\utils\\_validation.py\", line 410, in _sampling_strategy_float\n",
      "    raise ValueError(\n",
      "ValueError: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\noetr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.66591262 0.68712968\n",
      " 0.63572646 0.67495305 0.67495305 0.6928529         nan        nan\n",
      "        nan        nan 0.69216682 0.71977876 0.65125903 0.69201718\n",
      " 0.69201718 0.69366843        nan        nan        nan        nan\n",
      " 0.68405827 0.70253605 0.66542402 0.71886423 0.71886423 0.68556901\n",
      "        nan        nan        nan        nan 0.70364325 0.68436029\n",
      " 0.68385325 0.72684149 0.72684149 0.64884362        nan        nan\n",
      "        nan        nan 0.67236895 0.6714733  0.68385298 0.69542409\n",
      " 0.69542409 0.68699782        nan        nan        nan        nan\n",
      " 0.66348366 0.71425989 0.67380063 0.71516852 0.71516852 0.65039895\n",
      "        nan        nan        nan        nan 0.68297978 0.69345653\n",
      " 0.67628537 0.71057788 0.71057788 0.70392913        nan        nan\n",
      "        nan        nan 0.69203911 0.683641   0.68055213 0.71794145\n",
      " 0.71794145 0.66752737        nan        nan        nan        nan\n",
      " 0.6029838  0.71099465 0.7051344  0.73348144 0.73348144 0.6556985 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# setting up the pipline\n",
    "pipeline = ImPipeline([\n",
    "    ('smotenc', SMOTENC(categorical_features=categorical_feature_indices, random_state=42)),\n",
    "    ('perceptron', Perceptron(max_iter=1000, tol=1e-3, random_state=0))\n",
    "])\n",
    "\n",
    "# setting neighbors for the search to try\n",
    "param_grid = {\n",
    "    'smotenc__sampling_strategy': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.8, 1.0],  # Oversampling ratios to try\n",
    "    'smotenc__k_neighbors': [1, 2, 3, 4, 5, 6, 7, 9, 10]  # Number of nearest neighbors\n",
    "}\n",
    "\n",
    "# dropping the valid least significant  features via indicies\n",
    "X_train_dropped = np.delete(X_train, [40, 42], axis=1)\n",
    "X_valid_dropped = np.delete(X_valid, [40, 42], axis=1)\n",
    "\n",
    "# actually doing the grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_weighted', cv=5)\n",
    "grid_search.fit(X_train_dropped, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# using best estimator to predict on validation set\n",
    "best_estimator = grid_search.best_estimator_\n",
    "y_pred_valid = best_estimator.predict(X_valid_dropped)\n",
    "\n",
    "# printing f1 scores\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "f1_valid = f1_score(y_valid, y_pred_valid, average='weighted')\n",
    "print(f\"Validation F1 Score with GridSearch Optimized SMOTENC: {f1_valid:.4f}\")\n",
    "\n",
    "# priting f1 scores fopr both classes\n",
    "f1_scores_per_class_valid = f1_score(y_valid, y_pred_valid, average=None)\n",
    "print(\"Validation F1 Scores for Each Class with GridSearch Optimized SMOTENC:\", f1_scores_per_class_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
